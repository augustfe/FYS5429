\subsection{Hamiltonian Cycles and the Traveling Salesman}
Although the objectives of finding a Hamiltonian cycle in a graph and determining the route of a traveling salesman seem similar, the problems are in practice much less related in the domains which they are studied.
When looking for a Hamiltonian cycle, one typically starts out with a sparser graph.
An example of this could be a social graph of who knows who, where the aim is to pass a message around to each person.
Looking for a Hamiltonian cycle in a complete graph is a trivial exercise, simply visit each node in an arbitrary order.

On the other hand, the Traveling salesman problem typically concerns itself with complete graphs, or nearly so.
As discussed previously, GCNs do not function on complete graphs due to oversmoothing, and they are therefore not able to solve TSP natively.
\textcite{joshi2019efficient} overcame this through utilizing the $k$-nearest neighbour subgraph, training their network on a labeled dataset in order to predict a probabilistic heatmap of the viable edges.
This was then decoded with beam search in order to obtain the predicted tour.
The use of a labeled set limited their training to graphs with maximally 100 nodes, generalizing poorly with respect to larger graphs.

\textcite{FELLEK2024127392} utilized deep reinforcement learning in combination with an adapted Graph Attention Network (GAT) in their proposed Gated Deep Graph Attention Network (G-DGANet), constructing the final tour iteratively.
Their model was able to generalize better for larger graphs.

As these methods, and others like them, construct the final tour iteratively, the Hamiltonians described here are ill suited.
This stems from the fact that the bitstrings are constructed in order to make it easy to determine if a cycle exists, from a global prediction.
When a valid tour is constructed to begin with, this step is not necessary.

