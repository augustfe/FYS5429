%%%%%%%%%%%%%%%% README %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Place the BIBTeX entry in the right category 
% 
% BIBTeX labels:  {SurnameYear}, as in Albertsson2018
% Capitalized words in titles must be placed in {...}, as in:
%                       title = {Beyond the proton drip line: {Bayesian} analysis}
% Journal abbreviations:should be done according to the ISO4 standard:
%                       https://academic-accelerator.com/Journal-Abbreviation/System
% doi - include if possible
% url - include if possible
% do not include: abstract; eprint data, report numbers  for published papers;

%%%%%%%%%%%%%%%% XPINN %%%%%%%%%%%%%%%%

% Universal Approximation Theorem
@article{Cybenko1989ApproximationBS,
    title={Approximation by superpositions of a sigmoidal function},
    author={George V. Cybenko},
    journal={Mathematics of Control, Signals and Systems},
    year={1989},
    volume={2},
    pages={303-314},
    url={https://api.semanticscholar.org/CorpusID:3958369}
}

% Backpropogation
@article{Backpropogation1986,
  title={Learning representations by back-propagating errors},
  author={David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  journal={Nature},
  year={1986},
  volume={323},
  pages={533-536},
  url={https://api.semanticscholar.org/CorpusID:205001834}
}
% Natural Gradients
@misc{müller2023achieving,
      title={Achieving High Accuracy with PINNs via Energy Natural Gradients}, 
      author={Johannes Müller and Marius Zeinhofer},
      year={2023},
      eprint={2302.13163},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

%XPINNs
@article{Jagtap2020ExtendedPN,
    title={Extended {P}hysics-informed {N}eural {N}etworks ({XPINN}s): A Generalized Space-Time Domain Decomposition based Deep Learning Framework for Nonlinear Partial Differential Equations},
    author={Ameya Dilip Jagtap and George E. Karniadakis},
    journal={Communications in Computational Physics},
    year={2020},
    url={https://api.semanticscholar.org/CorpusID:229083388}
}

%XPINN follow-up: When do XPINNs generalize
@article{XPINN_generalize,
    author = {Hu, Zheyuan and Jagtap, Ameya D. and Karniadakis, George Em and Kawaguchi, Kenji},
    title = {When Do Extended Physics-Informed Neural Networks (XPINNs) Improve Generalization?},
    journal = {SIAM Journal on Scientific Computing},
    volume = {44},
    number = {5},
    pages = {A3158-A3182},
    year = {2022},
    doi = {10.1137/21M1447039},
    URL = {https://doi.org/10.1137/21M1447039},
    eprint = {https://doi.org/10.1137/21M1447039},
    abstract = { Physics-informed neural networks (PINNs) have become a popular choice for solving high-dimensional partial differential equations (PDEs) due to their excellent approximation power and generalization ability. Recently, extended PINNs (XPINNs) based on domain decomposition methods have attracted considerable attention due to their effectiveness in modeling multiscale and multiphysics problems and their parallelization. However, theoretical understanding of their convergence and generalization properties remains unexplored. In this study, we take an initial step towards understanding how and when XPINNs outperform PINNs. Specifically, for general multilayer PINNs and XPINNs, we first provide a prior generalization bound via the complexity of the target functions in the PDE problem and a posterior generalization bound via the posterior matrix norms of the networks after optimization. Moreover, based on our bounds, we analyze the conditions under which XPINNs improve generalization. Concretely, our theory shows that the key building block of XPINN, namely, the domain decomposition, introduces a tradeoff for generalization. On the one hand, XPINNs decompose the complex PDE solution into several simple parts, which decreases the complexity needed to learn each part and boosts generalization. On the other hand, decomposition leads to less training data being available in each subdomain, and hence such a model is typically prone to overfitting and may become less generalizable. Empirically, we choose five PDEs to show when XPINNs perform better than, similar to, or worse than PINNs, hence demonstrating and justifying our new theory. }
}

%PINNs
@article{RAISSI2019686,
    title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
    journal = {Journal of Computational Physics},
    volume = {378},
    pages = {686-707},
    year = {2019},
    issn = {0021-9991},
    doi = {https://doi.org/10.1016/j.jcp.2018.10.045},
    url = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
    author = {M. Raissi and P. Perdikaris and G.E. Karniadakis},
    keywords = {Data-driven scientific computing, Machine learning, Predictive modeling, Runge–Kutta methods, Nonlinear dynamics},
    abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.}
}

%cPINNs, XPINNs father
@ARTICLE{2020CMAME.36513028J,
       author = {{Jagtap}, Ameya D. and {Kharazmi}, Ehsan and {Karniadakis}, George Em},
        title = "{Conservative physics-informed neural networks on discrete domains for conservation laws: Applications to forward and inverse problems}",
      journal = {Computer Methods in Applied Mechanics and Engineering},
     keywords = {cPINN, Mortar PINN, Domain decomposition, Machine learning, Conservation laws, Inverse problems},
         year = 2020,
        month = jun,
       volume = {365},
          eid = {113028},
        pages = {113028},
          doi = {10.1016/j.cma.2020.113028},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020CMAME.36513028J},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

%APINNs, XPINNs son
@article{Hu_2023,
   title={Augmented Physics-Informed Neural Networks (APINNs): A gating network-based soft domain decomposition methodology},
   volume={126},
   ISSN={0952-1976},
   url={http://dx.doi.org/10.1016/j.engappai.2023.107183},
   DOI={10.1016/j.engappai.2023.107183},
   journal={Engineering Applications of Artificial Intelligence},
   publisher={Elsevier BV},
   author={Hu, Zheyuan and Jagtap, Ameya D. and Karniadakis, George Em and Kawaguchi, Kenji},
   year={2023},
   month=nov, pages={107183} }

%ADAM algorithm (AKA BADam)
@misc{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{reddi2019convergence,
      title={On the Convergence of {A}dam and Beyond}, 
      author={Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
      year={2019},
      eprint={1904.09237},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{deepmind2020jax,
  title = {The {D}eep{M}ind {JAX} {E}cosystem},
  author = {DeepMind and Babuschkin, Igor and Baumli, Kate and Bell, Alison and Bhupatiraju, Surya and Bruce, Jake and Buchlovsky, Peter and Budden, David and Cai, Trevor and Clark, Aidan and Danihelka, Ivo and Dedieu, Antoine and Fantacci, Claudio and Godwin, Jonathan and Jones, Chris and Hemsley, Ross and Hennigan, Tom and Hessel, Matteo and Hou, Shaobo and Kapturowski, Steven and Keck, Thomas and Kemaev, Iurii and King, Michael and Kunesch, Markus and Martens, Lena and Merzic, Hamza and Mikulik, Vladimir and Norman, Tamara and Papamakarios, George and Quan, John and Ring, Roman and Ruiz, Francisco and Sanchez, Alvaro and Sartran, Laurent and Schneider, Rosalia and Sezener, Eren and Spencer, Stephen and Srinivasan, Srivatsan and Stanojevi\'{c}, Milo\v{s} and Stokowiec, Wojciech and Wang, Luyu and Zhou, Guangyao and Viola, Fabio},
  url = {http://github.com/google-deepmind},
  year = {2020},
}

@misc{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

%%%%%%%%%%%%%%%%%  Published scientific articles  %%%%%%%%%%%%%%%%%%%


@article{Cristoforetti:2012su,
    author = "Cristoforetti, Marco and Di Renzo, Francesco and Scorzato, Luigi",
    collaboration = "AuroraScience",
    title = "{New approach to the sign problem in quantum field theories: High density QCD on a Lefschetz thimble}",
    doi = "10.1103/PhysRevD.86.074506",
    journal = "Phys. Rev. D",
    volume = "86",
    pages = "074506",
    year = "2012"
}


%%%%%%%%%%%%%%%%%  Books  %%%%%%%%%%%%%%%%%%%

@book{Goodfellow2016,
author ={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
title = {Deep Learning},
publisher = {The MIT Press, Cambridge, Massachusetts},
year = {2016}
}

@book{Bishop2006,
author = {Bishop, Christopher M.},
title = {Pattern Recognition and Machine Learning},
year = {2006},
publisher = {Springer Verlag, Berlin}
}

@book{Hastie2009,
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  publisher = {Springer Verlag, Berlin},
  title = {The Elements of Statistical Learning: Data Mining, Inference and Prediction},
  year = {2009}
}


@book{Murphy2012,
author = {Murphy, Kevin P.},
title = {Machine Learning: A Probabilistic Perspective},
year = {2012},
publisher = {The MIT Press, Cambdridge, Massachusetts}
}

@book{Schuld2018,
author = {Schuld, Maria and Petruccione, Francesco},
title = {Supervised Learning with Quantum Computers},
year = {2018},
publisher = {Springer Verlag, Berlin}
}


@book{Burkard2012, 
    author = {R.E. Burkard and M. Dell'Amico and S. Martello},
    title = {Assignment Problems},
    publisher = {SIAM, Philadelphia, USA},
    year = {2012}
}    

@BOOK{NAS-Models2012,
  author    = "{National Research Council}",
  title     = "Assessing the Reliability of Complex Models: Mathematical and Statistical Foundations of Verification, Validation, and Uncertainty Quantification",
  isbn      = "978-0-309-25634-6",
  doi       = "10.17226/13395",
  url       = "https://www.nap.edu/catalog/13395/assessing-the-reliability-of-complex-models-mathematical-and-statistical-foundations",
  year      = 2012,
  publisher = "The National Academies Press",
  address   = "Washington, DC"
}

%%%%%%%%%%%%%%%%%  REPORTS and THESES %%%%%%%%%%%%%%%%%%%

@techreport{Young2009,
  title = {Scientific grand challenges: forefront questions in nuclear science and the role of computing at the extreme scale},
  author = {Young, G. and Dean, D.J. and Savage, M.J.},
  year = {2009},
  address = {{Washington, D.C.}},
  institution = {U.S. Department of Energy},
  url="https://science.osti.gov/-/media/ascr/pdf/program-documents/docs/Np_report.pdf"
}



@phdthesis{Bradt2017,
author = {Bradt, Joshua William},
school = {Michigan State University},
title = {{Measurement of isobaric analogue resonances of 47Ar with the active target time projection chamber}},
URL={http://publications.nscl.msu.edu/thesis/\%20Brandt_2017_5279.pdf},
year = {2017}
}


%%%%%%%%%%%%%%%%%  Preprints %%%%%%%%%%%%%%%%%%%%%%%%%

@misc{pescia2021,
      title={Neural-Network Quantum States for Periodic Systems in Continuous Space}, 
      author={Gabriel Pescia and Jiequn Han and Alessandro Lovato and Jianfeng Lu and Giuseppe Carleo},
      year={2021},
      eprint={2112.11957},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}


%%%%%%%%%%%%%%%%%  Conference proceedings  %%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{Chen:2021jey,
    author = "Chen, Shi-Yang and Ding, Heng-Tong and Liu, Fei-Yi and Papp, Gabor and Yang, Chun-Bin",
    title = "{Machine learning Hadron Spectral Functions in Lattice QCD}",
    eprint = "2112.00460",
    archivePrefix = "arXiv",
    primaryClass = "hep-lat",
    month = "12",
    year = "2021"
}

